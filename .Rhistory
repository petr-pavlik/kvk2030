}
if (response$status_code == 206 || response$status_code == 200) {
# Download successful
message("Download complete.")
break
} else if (response$status_code == 416) {
# All data already downloaded
message("File already fully downloaded.")
break
} else {
message("Unexpected status code: ", response$status_code)
retries <- retries + 1
if (retries > max_retries) {
stop("Maximum number of retries reached. Download failed.")
}
}
}
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-00/Data/NecCDF/climate_inputs/e0/des.HERA1999.nc"
destfile <- "~/Desktop/largefile.zip"
download_large_file(url, destfile)
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-00/Data/NecCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "~/Desktop/largefile.zip"
download_large_file(url, destfile)
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NecCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "~/Desktop/largefile.zip"
download_large_file(url, destfile)
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "~/Desktop/largefile.zip"
download_large_file(url, destfile)
library(httr)
download_large_file <- function(url, destfile, max_retries = 5) {
# Check if the file already exists and get its size
existing_size <- if (file.exists(destfile)) file.info(destfile)$size else 0
# Open a connection to append to the file
con <- file(destfile, open = "ab")
on.exit(close(con))
retries <- 0
while (TRUE) {
# Add a "Range" header to request the remaining part of the file
headers <- if (existing_size > 0) {
c(Range = paste0("bytes=", existing_size, "-"))
} else {
NULL
}
# Perform the download
response <- try(GET(
url,
write_disk(destfile, append = TRUE),
add_headers(headers)
), silent = TRUE)
if (inherits(response, "try-error")) {
message("Download failed. Retrying...")
retries <- retries + 1
if (retries > max_retries) {
stop("Maximum number of retries reached. Download failed.")
}
Sys.sleep(2^retries)  # Exponential backoff
next
}
if (response$status_code == 206 || response$status_code == 200) {
# Download successful
message("Download complete.")
break
} else if (response$status_code == 416) {
# All data already downloaded
message("File already fully downloaded.")
break
} else {
message("Unexpected status code: ", response$status_code)
retries <- retries + 1
if (retries > max_retries) {
stop("Maximum number of retries reached. Download failed.")
}
}
}
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "e0_1966.nc"
download_large_file(url, destfile)
library(httr)
download_large_file <- function(url, destfile, max_retries = 5) {
# Check if the file already exists and get its size
existing_size <- if (file.exists(destfile)) file.info(destfile)$size else 0
retries <- 0
while (TRUE) {
# Add a "Range" header to request the remaining part of the file
headers <- if (existing_size > 0) {
c(
Range = paste0("bytes=", existing_size, "-"),
`User-Agent` = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
)
} else {
c(
`User-Agent` = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
)
}
# Perform the download
response <- try(GET(
url,
write_disk(destfile, append = TRUE),
add_headers(.headers = headers),
verbose()
), silent = TRUE)
if (inherits(response, "try-error")) {
message("Download failed. Retrying...")
retries <- retries + 1
if (retries > max_retries) {
stop("Maximum number of retries reached. Download failed.")
}
Sys.sleep(2^retries)  # Exponential backoff
next
}
if (response$status_code == 206 || response$status_code == 200) {
# Download successful
message("Download complete.")
break
} else if (response$status_code == 416) {
# All data already downloaded
message("File already fully downloaded.")
break
} else {
message("Unexpected status code: ", response$status_code)
retries <- retries + 1
if (retries > max_retries) {
stop("Maximum number of retries reached. Download failed.")
}
}
}
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "e0_1966.nc"
download_large_file(url, destfile)
download_large_file_curl <- function(url, destfile) {
# Construct the curl command
curl_cmd <- sprintf(
'curl -L -O -C - --retry 5 --retry-delay 5 -o "%s" "%s"',
destfile, url
)
# Execute the curl command
message("Starting download with curl...")
system(curl_cmd, intern = TRUE)
if (file.exists(destfile)) {
message("Download completed successfully: ", destfile)
} else {
stop("Download failed. Please check the URL or connection.")
}
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "e0_1966.nc"
download_large_file_curl(url, destfile)
download_large_file_curl <- function(url, destfile) {
# Construct the curl command
curl_cmd <- sprintf(
'curl -L --http1.1 -O -C - --retry 5 --retry-delay 5 -o "%s" "%s"',
destfile, url
)
# Execute the curl command
message("Starting download with curl...")
system(curl_cmd, intern = TRUE)
if (file.exists(destfile)) {
message("Download completed successfully: ", destfile)
} else {
stop("Download failed. Please check the URL or connection.")
}
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "e0_1966.nc"
download_large_file_curl(url, destfile)
}
# download_large_file_curl <- function(url, destfile) {
#   # Construct the curl command
#   curl_cmd <- sprintf(
#     'curl -L --http1.1 -O -C - --retry 5 --retry-delay 5 -o "%s" "%s"',
#     destfile, url
#   )
#
#   # Execute the curl command
#   message("Starting download with curl...")
#   system(curl_cmd, intern = TRUE)
#
#   if (file.exists(destfile)) {
#     message("Download completed successfully: ", destfile)
#   } else {
#     stop("Download failed. Please check the URL or connection.")
#   }
# }
#
# # Example usage
# url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
# destfile <- "e0_1966.nc"
# download_large_file_curl(url, destfile)
download_large_file_segmented <- function(url, destfile, chunk_size = 100 * 1024^2, max_retries = 5) {
# Get file size from server
get_file_size <- function(url) {
headers <- system(sprintf('curl -sI "%s"', url), intern = TRUE)
size_line <- grep("Content-Length", headers, value = TRUE)
as.numeric(gsub("Content-Length: ", "", size_line))
}
file_size <- get_file_size(url)
if (is.na(file_size)) stop("Unable to determine file size.")
message("Total file size: ", file_size, " bytes")
# Download each segment
parts <- ceiling(file_size / chunk_size)
temp_files <- vector("list", parts)
for (i in seq_len(parts)) {
start <- (i - 1) * chunk_size
end <- min(i * chunk_size - 1, file_size - 1)
temp_file <- sprintf("%s.part%03d", destfile, i)
temp_files[[i]] <- temp_file
if (file.exists(temp_file)) {
message(sprintf("Part %d already exists, skipping download.", i))
next
}
retries <- 0
repeat {
message(sprintf("Downloading part %d: bytes %d-%d", i, start, end))
curl_cmd <- sprintf(
'curl -L --http1.1 --retry 5 --retry-delay 5 -r %d-%d -o "%s" "%s"',
start, end, temp_file, url
)
result <- system(curl_cmd, intern = TRUE)
if (file.exists(temp_file) && file.info(temp_file)$size == (end - start + 1)) {
message(sprintf("Part %d downloaded successfully.", i))
break
} else {
retries <- retries + 1
if (retries > max_retries) {
stop(sprintf("Failed to download part %d after %d retries.", i, max_retries))
}
message(sprintf("Retrying part %d...", i))
}
}
}
# Combine parts into a single file
message("Combining parts into final file...")
file.create(destfile)
for (temp_file in temp_files) {
system(sprintf('cat "%s" >> "%s"', temp_file, destfile))
file.remove(temp_file)
}
message("Download complete: ", destfile)
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "e0_1966.nc"
download_large_file_segmented(url, destfile)
download_large_file_segmented <- function(url, destfile, chunk_size = 100 * 1024^2, max_retries = 5) {
# Get file size from server
get_file_size <- function(url) {
headers <- system(sprintf('curl -sI "%s"', url), intern = TRUE)
size_line <- grep("Content-Length", headers, value = TRUE)
as.numeric(gsub("Content-Length: ", "", size_line))
}
file_size <- get_file_size(url)
if (is.na(file_size)) stop("Unable to determine file size.")
message("Total file size: ", file_size, " bytes")
# Download each segment
parts <- ceiling(file_size / chunk_size)
temp_files <- vector("list", parts)
for (i in seq_len(parts)) {
start <- (i - 1) * chunk_size
end <- min(i * chunk_size - 1, file_size - 1)
temp_file <- sprintf("%s.part%03d", destfile, i)
temp_files[[i]] <- temp_file
if (file.exists(temp_file)) {
message(sprintf("Part %d already exists, skipping download.", i))
next
}
retries <- 0
repeat {
message(sprintf("Downloading part %d: bytes %d-%d", i, start, end))
curl_cmd <- sprintf(
'curl -L --http1.1 --retry 5 --retry-delay 5 -r %d-%d -o "%s" "%s"',
start, end, temp_file, url
)
result <- system(curl_cmd, intern = TRUE)
if (file.exists(temp_file) && file.info(temp_file)$size == (end - start + 1)) {
message(sprintf("Part %d downloaded successfully.", i))
break
} else {
retries <- retries + 1
if (retries > max_retries) {
stop(sprintf("Failed to download part %d after %d retries.", i, max_retries))
}
message(sprintf("Retrying part %d...", i))
}
}
}
# Combine parts into a single file
message("Combining parts into final file...")
file.create(destfile)
for (temp_file in temp_files) {
system(sprintf('cat "%s" >> "%s"', temp_file, destfile))
file.remove(temp_file)
}
message("Download complete: ", destfile)
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "e0_1966.nc"
download_large_file_segmented(url, destfile)
# download_large_file_curl <- function(url, destfile) {
#   # Construct the curl command
#   curl_cmd <- sprintf(
#     'curl -L --http1.1 -O -C - --retry 5 --retry-delay 5 -o "%s" "%s"',
#     destfile, url
#   )
#
#   # Execute the curl command
#   message("Starting download with curl...")
#   system(curl_cmd, intern = TRUE)
#
#   if (file.exists(destfile)) {
#     message("Download completed successfully: ", destfile)
#   } else {
#     stop("Download failed. Please check the URL or connection.")
#   }
# }
#
# # Example usage
# url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
# destfile <- "e0_1966.nc"
# download_large_file_curl(url, destfile)
download_large_file_segmented <- function(url, destfile, chunk_size = 100 * 1024^2, max_retries = 5) {
# Get file size from server
get_file_size <- function(url) {
headers <- system(sprintf('curl -sI "%s"', url), intern = TRUE)
size_line <- grep("Content-Length", headers, value = TRUE)
if (length(size_line) > 0) {
return(as.numeric(gsub("Content-Length: ", "", size_line)))
} else {
message("Unable to determine file size from server. Headers received:\n", paste(headers, collapse = "\n"))
return(NA)
}
}
file_size <- get_file_size(url)
if (is.na(file_size)) stop("Unable to determine file size. Check server response or URL.")
message("Total file size: ", file_size, " bytes")
# Download each segment
parts <- ceiling(file_size / chunk_size)
temp_files <- vector("list", parts)
for (i in seq_len(parts)) {
start <- (i - 1) * chunk_size
end <- min(i * chunk_size - 1, file_size - 1)
temp_file <- sprintf("%s.part%03d", destfile, i)
temp_files[[i]] <- temp_file
if (file.exists(temp_file)) {
message(sprintf("Part %d already exists, skipping download.", i))
next
}
retries <- 0
repeat {
message(sprintf("Downloading part %d: bytes %d-%d", i, start, end))
curl_cmd <- sprintf(
'curl -L --http1.1 --retry 5 --retry-delay 5 -r %d-%d -o "%s" "%s"',
start, end, temp_file, url
)
result <- system(curl_cmd, intern = TRUE)
if (file.exists(temp_file) && file.info(temp_file)$size == (end - start + 1)) {
message(sprintf("Part %d downloaded successfully.", i))
break
} else {
retries <- retries + 1
if (retries > max_retries) {
stop(sprintf("Failed to download part %d after %d retries.", i, max_retries))
}
message(sprintf("Retrying part %d...", i))
}
}
}
# Combine parts into a single file
message("Combining parts into final file...")
file.create(destfile)
for (temp_file in temp_files) {
system(sprintf('cat "%s" >> "%s"', temp_file, destfile))
file.remove(temp_file)
}
# download_large_file_curl <- function(url, destfile) {
#   # Construct the curl command
#   curl_cmd <- sprintf(
#     'curl -L --http1.1 -O -C - --retry 5 --retry-delay 5 -o "%s" "%s"',
#     destfile, url
#   )
#
#   # Execute the curl command
#   message("Starting download with curl...")
#   system(curl_cmd, intern = TRUE)
#
#   if (file.exists(destfile)) {
#     message("Download completed successfully: ", destfile)
#   } else {
#     stop("Download failed. Please check the URL or connection.")
#   }
# }
#
# # Example usage
# url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
# destfile <- "e0_1966.nc"
# download_large_file_curl(url, destfile)
download_large_file_segmented <- function(url, destfile, chunk_size = 100 * 1024^2, max_retries = 5) {
# Get file size from server
get_file_size <- function(url) {
headers <- system(sprintf('curl -sI "%s"', url), intern = TRUE)
size_line <- grep("Content-Length", headers, value = TRUE)
if (length(size_line) > 0) {
return(as.numeric(gsub("Content-Length: ", "", size_line)))
} else {
message("Unable to determine file size from server. Headers received:\n", paste(headers, collapse = "\n"))
return(NA)
}
}
file_size <- get_file_size(url)
if (is.na(file_size)) stop("Unable to determine file size. Check server response or URL.")
message("Total file size: ", file_size, " bytes")
# Download each segment
parts <- ceiling(file_size / chunk_size)
temp_files <- vector("list", parts)
for (i in seq_len(parts)) {
start <- (i - 1) * chunk_size
end <- min(i * chunk_size - 1, file_size - 1)
temp_file <- sprintf("%s.part%03d", destfile, i)
temp_files[[i]] <- temp_file
if (file.exists(temp_file)) {
message(sprintf("Part %d already exists, skipping download.", i))
next
}
retries <- 0
repeat {
message(sprintf("Downloading part %d: bytes %d-%d", i, start, end))
curl_cmd <- sprintf(
'curl -L --http1.1 --retry 5 --retry-delay 5 -r %d-%d -o "%s" "%s"',
start, end, temp_file, url
)
result <- system(curl_cmd, intern = TRUE)
if (file.exists(temp_file) && file.info(temp_file)$size == (end - start + 1)) {
message(sprintf("Part %d downloaded successfully.", i))
break
} else {
retries <- retries + 1
if (retries > max_retries) {
stop(sprintf("Failed to download part %d after %d retries.", i, max_retries))
}
message(sprintf("Retrying part %d...", i))
}
}
}
# Combine parts into a single file
message("Combining parts into final file...")
file.create(destfile)
for (temp_file in temp_files) {
system(sprintf('cat "%s" >> "%s"', temp_file, destfile))
file.remove(temp_file)
}
message("Download complete: ", destfile)
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "e0_1966.nc"
download_large_file_segmented(url, destfile)
download_large_file_curl <- function(url, destfile) {
# Construct the curl command
curl_cmd <- sprintf(
'curl -L --http1.1 -O -C - --retry 5 --retry-delay 5 -o "%s" "%s"',
destfile, url
)
# Execute the curl command
message("Starting download with curl...")
system(curl_cmd, intern = TRUE)
if (file.exists(destfile)) {
message("Download completed successfully: ", destfile)
} else {
stop("Download failed. Please check the URL or connection.")
}
}
# Example usage
url <- "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/HERA/VER1-0/Data/NetCDF/climate_inputs/e0/e0_1966.nc"
destfile <- "e0_1966.nc"
download_large_file_curl(url, destfile)
A <- kvk2030::novaSitPovodi()
A
A <- kvk2030::getSitPovodiParameter()
A <- kvk2030::novaSitPovodi()
kvk2030::getSitPovodiParameter(A)
kvk2030::getSitPovodiParameter(A)
Dyje <- kvk2030::novaSitPovodi()
kvk2030::getSitPovodiParameter(Dyje)
rm(a)
rm(A)
kvk2030::getSitPovodiParameter(Dyje)
fls <- list.files(path = "~/Downloads/Viir Karhov/", pattern = "*.csv", full.names = TRUE)
fls
lapply(fls, FUN = \(x) read_csv)
lapply(fls, FUN = \(x) read.csv)
y <- lapply(fls, FUN = \(x) read.csv)
y <- lapply(fls, FUN = read.csv)
y <- rbindlist(lapply(fls, FUN = read.csv))
y <- data.table::rbindlist(lapply(fls, FUN = read.csv))
rm(y)
?wrmt::BurrDistributions
?wrmt::`+.PDM`
?wrmt::PDM
?wrmt::eckhardt
?wrmt::lyne_hollick
